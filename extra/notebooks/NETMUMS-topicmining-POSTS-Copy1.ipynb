{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re \n",
    "import time\n",
    "%load_ext jupyternotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pattern.en import parse, Sentence\n",
    "from pattern.en import modality, mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(text):\n",
    "    sentence_separators = re.findall('[\\n?!.]+', text) + ['']\n",
    "    sentences = re.split('[\\n?!.]+', text)\n",
    "    for ind, _ in enumerate(sentence_separators): #we keep the punctuation which sep sentences bc question marks are used in modality calculation.\n",
    "        sentences[ind] += sentence_separators[ind]\n",
    "    return sentences\n",
    "\n",
    "def parse_and_get_m(text, get_mood=False, get_modal=True):\n",
    "    \"\"\"\n",
    "    Split sentences, parse and get modality of sentences, then return the mean of the modalities. (or something, #TODO)\n",
    "    We need to split sentences because sentence structure is parsed. In sentiment anal it uses bag of words instead #TODO: verify this. I know nltk uses bag of words\n",
    "    \"\"\"\n",
    "    sents= [Sentence(parse(s, lemmata=True)) for s in split_sentences(text)] #I don't think the punctuations are used in modality or mood detection.\n",
    "    ## Debug note: i forgot to parse and convert to Sentence object, but it ran fine.\n",
    "    ## Now I have added this step because it was throwing an error.\n",
    "    ## However it also goes much slower now!\n",
    "    if get_mood:\n",
    "        if get_modal:\n",
    "            return [(modality(s), mood(s)) for s in sents]\n",
    "        else:\n",
    "            return [ mood(s) for s in sents]\n",
    "    elif get_modal:\n",
    "        return [modality(s) for s in sents]\n",
    "    else:\n",
    "        return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_text  = \"\"\"\n",
    "we had a rat earlier this year. it took to snoozing in bin! apparently because they are nice and warm. just put bait down. when that didn't work he put a sticky pad down to catch it in my bin and traps (the deadly type! ) around the hole it through. the sticky pad came after he tried to get it with his air gun. so i think its safe to say really aren't that bothered about humane traps! obviously you can't keep cats out of others gardens but you can't expect anyone else to pander to your pets. i'm sure cat owners don't generally keep their pets in, in case their cats poop makes the neighbours kids ill! same thing really imo. as a childminder i expect her main prioroty is to get rid of the rat and any potential family members asap. not be faffing with traps for goodness knows how long as whilst they are all caught.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pattern.en said no.\n",
      "pattern.en said no.\n",
      "pattern.en said ok.\n",
      "pattern.en said ok.\n",
      "pattern.en said ok.\n"
     ]
    }
   ],
   "source": [
    "#The current version (3.6) of pattern has been unmaintained and the fix for this has not been implemented.\n",
    "#This is a hacky method of getting around the error\n",
    "#I suggest that you modify the pattern package yourself as described here (https://github.com/clips/pattern/issues/308)\n",
    "\n",
    "#This hacky fix is included in order to maintain compatibility for those who have just installed the package.\n",
    "def pattern_workaround():\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i == 0:\n",
    "        j += 1\n",
    "        try:\n",
    "            modality(Sentence(parse('''Please stop giving me StopIteration Error!''')))\n",
    "            if j > 4:\n",
    "                i += 1\n",
    "            print('pattern.en said ok.')\n",
    "        except RuntimeError:\n",
    "            print('pattern.en said no.')\n",
    "            pass\n",
    "pattern_workaround()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modality('''\n",
    "a little hack: we need to run modality four times to get it to work,\n",
    "otherwise it will return RuntimeError: generator raised StopIteration\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 0.4166666666666667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.5357142857142857,\n",
       " 0.125,\n",
       " 0.08333333333333333,\n",
       " 0.75,\n",
       " 0.4166666666666667,\n",
       " 0.75,\n",
       " 1.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Split sentences, parse and get modality of sentences, then return the mean of the modalities. (or something, #TODO)\n",
    "We need to split sentences because sentence structure is parsed. In sentiment anal it uses bag of words instead #TODO: verify this. I know nltk uses bag of words\n",
    "\"\"\"\n",
    "\n",
    "get_mood=False\n",
    "get_modal=True\n",
    "\n",
    "\n",
    "sents= [Sentence(parse(s, lemmata=True)) for s in split_sentences(debug_text)] #I don't think the punctuations are used in modality or mood detection.\n",
    "## Debug note: i forgot to parse and convert to Sentence object, but it ran fine.\n",
    "## Now I have added this step because it was throwing an error.\n",
    "## However it also goes much slower now!\n",
    "\n",
    "[modality(s) for s in sents]\n",
    "[modality(s) for s in sents]\n",
    "[modality(s) for s in sents]\n",
    "[modality(s) for s in sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.75,\n",
       " 1.0,\n",
       " 0.25,\n",
       " 1.0,\n",
       " 0.4166666666666667,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.5357142857142857,\n",
       " 0.125,\n",
       " 0.08333333333333333,\n",
       " 0.75,\n",
       " 0.4166666666666667,\n",
       " 0.75,\n",
       " 1.0]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_and_get_m(debug_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## DEBUG\n",
    "##\n",
    "## it always runs on the fourth attempt.\n",
    "## It doesn't work like 4 times, and after 4 times trying to run it it will work... wtf???\n",
    "## Make a new notebook where we run only this stuff to test it with this weird quirk and easily re-run .\n",
    "## For now the easiest work aorund is to keep retrying until it works... lol.\n",
    "## I think I didn't even need to add my own conversion code. \n",
    "## #TODO: check their code and check my results to see if I should remove. BC its way faster without it!!!!\n",
    "##\n",
    "#run it\n",
    "start = time.time()\n",
    "temp = [('bird', parse_and_get_m(i)) for i in [debug_text]]\n",
    "#i should just try running it in a for loop?\n",
    "#its easier to debug and this type of thign cant be vectorized anyways so i doubt theres any benefit to using list form\n",
    "keys, modalities_by_sentence = zip(*temp)\n",
    "end = time.time()\n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## DEBUG\n",
    "##\n",
    "\n",
    "def dbg_parse_and_get_m(text, get_mood=False, get_modal=True):\n",
    "    \"\"\"\n",
    "    Split sentences, parse and get modality of sentences, then return the mean of the modalities. (or something, #TODO)\n",
    "    We need to split sentences because sentence structure is parsed. In sentiment anal it uses bag of words instead #TODO: verify this. I know nltk uses bag of words\n",
    "    \"\"\"\n",
    "    sents= split_sentences(text) #I don't think the punctuations are used in modality or mood detection.\n",
    "    ## Debug note: i forgot to parse and convert to Sentence object, but it ran fine.\n",
    "    ## Now I have added this step because it was throwing an error.\n",
    "    ## However it also goes much slower now!\n",
    "    if get_mood:\n",
    "        if get_modal:\n",
    "            return [(modality(s), mood(s)) for s in sents]\n",
    "        else:\n",
    "            return [ mood(s) for s in sents]\n",
    "    elif get_modal:\n",
    "        return [modality(s) for s in sents]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    \n",
    "start = time.time()\n",
    "temp = [(key, dbg_parse_and_get_m(posts_dict[key]['body'])) for key in class_df.index]\n",
    "#i should just try running it in a for loop?\n",
    "#its easier to debug and this type of thign cant be vectorized anyways so i doubt theres any benefit to using list form\n",
    "keys, modalities_by_sentence = zip(*temp)\n",
    "end = time.time()\n",
    "%notify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "## DEBUG: compare teh results of both ways.\n",
    "## and the speeds.\n",
    "##\n",
    "\n",
    "end - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run it\n",
    "start = time.time()\n",
    "keys, modalities_by_sentence = zip(*[(key, parse_and_get_m(posts_dict[key]['body'])) for key in class_df.index])\n",
    "end = time.time()\n",
    "%notify\n",
    "\n",
    "#prepare datatypes and add to dataframe\n",
    "mean, var = zip(*[(np.mean(x), np.var(x)) for x in modalities_by_sentence])\n",
    "del modalities_by_sentence\n",
    "\n",
    "class_df['modality_sentence_mean'], class_df['modality_sentence_var'] =  pd.Series(mean, index=keys), pd.Series(var, index=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to generate colors for denisty of points of scatter plot.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde as kde\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib import cm\n",
    "#source: https://stackoverflow.com/questions/19064772/visualization-of-scatter-plots-with-overlapping-points-in-matplotlib\n",
    "\n",
    "def makeColours( vals ):\n",
    "    colours = np.zeros( (len(vals),3) )\n",
    "    norm = Normalize( vmin=vals.min(), vmax=vals.max() )\n",
    "\n",
    "    #Can put any colormap you like here.\n",
    "    colours = [cm.ScalarMappable( norm=norm, cmap='jet').to_rgba( val ) for val in vals]\n",
    "\n",
    "    return colours\n",
    "\n",
    "def get_cols_and_array_from_df(df, first_col:str,second_col:str):\n",
    "    #we need to use a np array for kde, and make sure its the correct shape\n",
    "    sample = np.array(list((zip(*np.array(df[[first_col,second_col]])))))\n",
    "\n",
    "    #calculate densities per point\n",
    "    densObj = kde(np.array(list((zip(*np.array(df[[first_col,second_col]]))))))\n",
    "    # generate colormap\n",
    "    colours = makeColours( densObj.evaluate( sample ) )\n",
    "    return sample, colours\n",
    "\n",
    "def heat_scatter(df, first_col:str, second_col:str, point_size=2):\n",
    "    sample, colours = get_cols_and_array_from_df(df, first_col, second_col)\n",
    "    plt.scatter(y=sample[0],x=sample[1], color=colours, s=point_size)\n",
    "    plt.xlabel(first_col)\n",
    "    plt.ylabel(second_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "heat_scatter(class_df, 'modality_sentence_var','modality_sentence_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_scatter(class_df, 'sentiment','subjectivity', point_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "for category in list(class_df['product_type'].value_counts().index): #get the non-zero labels (zero labels may create an error)\n",
    "    num_of_posts = class_df.loc[class_df.product_type == category]\n",
    "    size_for_cat = 20./np.log(len(num_of_posts)) #make points bigger when theres less data to show.\n",
    "    heat_scatter(num_of_posts, 'sentiment','subjectivity', point_size=size_for_cat)\n",
    "    plt.title(category + ': %s points' % len(num_of_posts))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df.loc[class_df['sentiment'] < 0.05].loc[class_df['subjectivity'] < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heat_scatter(class_df.loc[class_df['sentiment'] < 0.05].loc[class_df['subjectivity'] < 0.1], 'sentiment', 'subjectivity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_lower_sentiment = len(class_df.loc[class_df['sentiment'] < 0.05])\n",
    "num_higher_sentiment = len(class_df.loc[class_df['sentiment'] >= 0.05])\n",
    "print((num_lower_sentiment, num_higher_sentiment))\n",
    "\n",
    "num_lower_subj = len(class_df.loc[class_df['subjectivity'] < 0.1])\n",
    "num_higher_subj = len(class_df.loc[class_df['subjectivity'] >= 0.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,4)})\n",
    "for category in list(class_df['product_type'].value_counts().index): #get the non-zero labels (zero labels may create an error)\n",
    "    num_of_posts = class_df.loc[class_df.product_type == category]\n",
    "    size_for_cat = 20./np.log(len(num_of_posts)) #make points bigger when theres less data to show.\n",
    "    heat_scatter(num_of_posts, 'modality_sentence_mean','subjectivity', point_size=size_for_cat)\n",
    "    plt.title(category + ': %s points' % len(num_of_posts))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback #needed to store full error tracebacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errs = []\n",
    "for haz in hazards.keys():\n",
    "    posts_for_hazard = class_df.loc[(class_df[haz] > 0)]\n",
    "    try:\n",
    "        size_for_cat = 20./np.log(len(posts_for_hazard)) #make points bigger when theres less data to show.\n",
    "        heat_scatter(posts_for_hazard, 'sentiment','subjectivity', point_size=size_for_cat)\n",
    "        plt.title(haz + ': %s points' % len(posts_for_hazard))\n",
    "        plt.show()\n",
    "    except ValueError:\n",
    "        print(haz + ': insufficient data')\n",
    "    except Exception as exc:\n",
    "        errs.append(haz + ' ' + str(exc))\n",
    "        errs.append(str(traceback.format_exc()))\n",
    "print('\\n'.join(errs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys, modalities_by_sentence = zip(*[(key, parse_and_get_m(posts_dict[key]['body'])) for key in class_df.index])\n",
    "\n",
    "temp=  pd.Series(modalities_by_sentence, index=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(5,8)})\n",
    "sns.boxplot(x='sentiment', y='product_type', data=class_df)\n",
    "\n",
    "#boxplot outlier detection:\n",
    "#using a method that is a function of the inter-quartile range.\n",
    "#https://seaborn.pydata.org/generated/seaborn.boxplot.html#seaborn.boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make classification for hazards and check it as well.\n",
    "class_df['hazard_type'] = class_df[hazards.keys()].idxmax(axis=1)\n",
    "class_df.loc[class_df[hazards.keys()].max(axis=1) == 0,'hazard_type'] = 'NA'\n",
    "class_df['hazard_type'] = class_df['hazard_type'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(4,12)})\n",
    "sns.boxenplot(x='sentiment', y='hazard_type', data=class_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may seem strange that these terms have positive sentiment. Keep in mind that we are looking at the sentiment in the entire post where the term occurs, and people are netmums are quite often very friendly to each other when replying.\n",
    "\n",
    "#TODO: use only subset of terms around the phrases! (non-per  post approach probablY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_df['hazard_type'].value_counts()\n",
    "#all of out important categories are less than 200.\n",
    "#this is not ideal use for letter plot (aka boxen plot) but we are\n",
    "#1) interested in the distribution for NA\n",
    "#2) \n",
    "\n",
    "# after looking at the paper I think simple boxplot is a better choice for our data. In each category data is mostly normal,\n",
    "# and we have very few points anyways so plotitng the points with strip plot is quite indicative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(4,12)})\n",
    "sns.boxplot(x='subjectivity', y='hazard_type', data=class_df, fliersize=0, linewidth=1)\n",
    "#sns.boxenplot(x='subjectivity', y='hazard_type', data=class_df, k_depth='full', showfliers=False)\n",
    "sns.stripplot(x='subjectivity', y='hazard_type', data=class_df, color='black', alpha=0.8, jitter=0.07, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxstrip(x_name:str, y_name:str, df=class_df):\n",
    "    sns.boxplot(x=x_name, y=y_name, data=df, fliersize=0, linewidth=1)\n",
    "    #sns.boxenplot(x='subjectivity', y='hazard_type', data=class_df, k_depth='full', showfliers=False)\n",
    "    sns.stripplot(x=x_name, y=y_name, data=df, color='black', alpha=0.8, jitter=0.07, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxstrip('modality_sentence_mean','hazard_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Occurences of Hazard Term by Category\n",
    "this is just to get an idea what type of regression should be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign the max to it's own col to graph easily\n",
    "class_df['count_for_classified_hazard'] =class_df[hazards.keys()].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(4,8)})\n",
    "sns.boxenplot(x='count_for_classified_hazard', y='hazard_type', data=class_df, k_depth='full', showfliers=False)\n",
    "sns.stripplot(x='count_for_classified_hazard', y='hazard_type', data=class_df, color='black', alpha=0.5, jitter=0.4, size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit(data=class_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
